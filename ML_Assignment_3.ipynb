{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DLAqY_HiuRmC",
    "outputId": "73be6caf-1e67-4b7c-a004-a7c97f6f05b0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(\"/content/USA_Housing.csv\")\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_Bbkw5yuuXR"
   },
   "source": [
    "Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Square Error Fit)  \n",
    "Download the dataset regarding USA House Price Prediction from the following link:  \n",
    "https://drive.google.com/file/d/1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX/view?usp=sharing  \n",
    "Load the dataset and Implement 5- fold cross validation for multiple linear regression\n",
    "(using least square error fit).  \n",
    "Steps:  \n",
    "a) Divide the dataset into input features (all columns except price) and output variable  \n",
    "(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpCenkFyutHH"
   },
   "outputs": [],
   "source": [
    "x=data.drop('Price',axis=1)\n",
    "y=data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6kftk_Vu9ts"
   },
   "source": [
    "b) Scale the values of input features.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKsqmTvXvClr",
    "outputId": "9690477a-58ae-4575-c93b-ff02651651aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.02865969 -0.29692705  0.02127433  0.08806222 -1.31759867]\n",
      " [ 1.00080775  0.02590164 -0.25550611 -0.72230146  0.40399945]\n",
      " [-0.68462915 -0.11230283  1.5162435   0.93084045  0.07240989]\n",
      " ...\n",
      " [-0.48723454  1.28447022 -2.17026949 -1.50025059 -0.29193658]\n",
      " [-0.05459152 -0.44669439  0.14154061  1.18205319  0.65111608]\n",
      " [-0.28831272  0.01521477 -0.19434166  0.07185495  1.04162464]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "x=preprocessing.scale(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFSzjwwLwG1M"
   },
   "source": [
    "c) Divide input and output features into five folds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiLs-wmkv3mP",
    "outputId": "746bd98a-51ab-49ff-e188-da00e6a46ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmjB2gR5w46E"
   },
   "source": [
    "\n",
    "d) Run five iterations, in each iteration consider one-fold as test set and remaining\n",
    "four sets as training set. Find the beta (ùõΩ) matrix, predicted values, and R2_score\n",
    "for each iteration using least square error fit.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUDD69hXw0Y_",
    "outputId": "b354ee7f-a6d4-493d-f35a-d53647d5bc57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold R2 Score: 0.9179971706985147\n",
      "Fold Beta Matrix: [230745.94073479 163243.27314515 120309.77397759   3011.45976111\n",
      " 151552.63069359]\n",
      "--------------------\n",
      "Fold R2 Score: 0.9145677884802819\n",
      "Fold Beta Matrix: [229081.97914235 165882.1605634  121536.57475055   2092.4478622\n",
      " 150874.99274586]\n",
      "--------------------\n",
      "Fold R2 Score: 0.9116116385364478\n",
      "Fold Beta Matrix: [230224.50511001 162766.17455493 121022.77324577   1247.16258975\n",
      " 150234.77720419]\n",
      "--------------------\n",
      "Fold R2 Score: 0.9193091764960816\n",
      "Fold Beta Matrix: [229500.10043209 165212.07110924 122839.9376815    3063.71699324\n",
      " 150917.88484984]\n",
      "--------------------\n",
      "Fold R2 Score: 0.9243869413350316\n",
      "Fold Beta Matrix: [230225.0513193  163956.83884606 121115.12045628    783.46716975\n",
      " 150662.44678192]\n",
      "--------------------\n",
      "\n",
      "Average R2 Score: 0.9175745431092714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "beta_matrices = []\n",
    "predicted_values = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    beta_matrices.append(model.coef_)\n",
    "    predicted_values.append(y_pred)\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"Fold R2 Score: {r2_scores[-1]}\")\n",
    "    print(f\"Fold Beta Matrix: {beta_matrices[-1]}\")\n",
    "    print(\"-\" * 20)\n",
    "print(\"\")\n",
    "print(\"Average R2 Score:\", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMXH9PESxV7l"
   },
   "source": [
    "e) Use the best value of (ùõΩ) matrix (for which R2_score is maximum), to train the regressor for 70% of data and test the performance for remaining 30% data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IUlNFTcxRhd",
    "outputId": "df143ee0-1eb7-4773-b5ad-dfa09f1a02da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score on 70/30 split using model trained on 70% data: 0.9146818498916267\n",
      "Beta Matrix from model trained on 70% data: [230464.52520478 164159.19982569 120514.71328324   2913.62424674\n",
      " 151019.35865135]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Identify the best beta matrix based on maximum R2 score\n",
    "best_r2_idx = np.argmax(r2_scores)\n",
    "best_coefficients = beta_matrices[best_r2_idx]\n",
    "\n",
    "# Split data into training (70%) and testing (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = lin_reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"R¬≤ Score (70/30 split): {test_r2:.4f}\")\n",
    "print(f\"Model Coefficients (Beta Matrix): {lin_reg_model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8eE4MbVyQTn"
   },
   "source": [
    "**Q2.** Concept of Validation set for Multiple Linear Regression (Gradient Descent  \n",
    "Optimization).Consider the same dataset of Q1, rather than dividing the dataset into five folds, divide the\n",
    "dataset into training set (56%), validation set (14%), and test set (30%). Consider four different values of learning rate i.e. {0.001,0.01,0.1,1}. Compute the values of\n",
    "regression coefficients for each value of learning rate after 1000 iterations. For each set of regression coefficients, compute R2_score for validation and test set and find the best value of regession coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OA-_vNzvy8N1",
    "outputId": "cff9fbdb-50a9-4893-c496-e7849b134c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate = 0.001\n",
      "R¬≤ on Validation Set: -0.799334149357984\n",
      "R¬≤ on Test Set: -0.9872590714052005\n",
      "Beta Coefficients:\n",
      " [779274.02090139 146658.52639308 103040.26919133  72303.5523883\n",
      "  24381.66647824] ...\n",
      "----------------------------------------\n",
      "Learning Rate = 0.01\n",
      "R¬≤ on Validation Set: 0.909818561206292\n",
      "R¬≤ on Test Set: 0.9147438859798211\n",
      "Beta Coefficients:\n",
      " [1232381.36998704  234542.29331285  162395.51342821  121485.70570465\n",
      "    3089.76469737] ...\n",
      "----------------------------------------\n",
      "Learning Rate = 0.1\n",
      "R¬≤ on Validation Set: 0.9097995626742029\n",
      "R¬≤ on Test Set: 0.9147570103083724\n",
      "Beta Coefficients:\n",
      " [1232434.57572502  234562.99454568  162415.95445045  121760.31153933\n",
      "    2814.16200824] ...\n",
      "----------------------------------------\n",
      "Learning Rate = 1\n",
      "R¬≤ on Validation Set: 0.9097995626742028\n",
      "R¬≤ on Test Set: 0.9147570103083724\n",
      "Beta Coefficients:\n",
      " [1232434.57572502  234562.99454568  162415.95445045  121760.31153933\n",
      "    2814.16200824] ...\n",
      "----------------------------------------\n",
      "\n",
      "Best Learning Rate: 0.01\n",
      "Best Validation R¬≤: 0.909818561206292\n",
      "Best Beta Coefficients:\n",
      " [1232381.36998704  234542.29331285  162395.51342821  121485.70570465\n",
      "    3089.76469737  151581.05530854]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load dataset\n",
    "housing_data = pd.read_csv(\"USA_Housing.csv\")\n",
    "X_features = housing_data.drop(columns=['Price']).values\n",
    "y_target = housing_data['Price'].values.reshape(-1, 1)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_features, y_target, test_size=0.30, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.20, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Add bias column\n",
    "def add_bias_column(X):\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "X_train_bias = add_bias_column(X_train)\n",
    "X_val_bias = add_bias_column(X_val)\n",
    "X_test_bias = add_bias_column(X_test)\n",
    "\n",
    "# Gradient descent implementation\n",
    "def gradient_descent_solver(X, y, learning_rate, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    coefficients = np.zeros((n, 1))\n",
    "    for _ in range(iterations):\n",
    "        gradient = (1/m) * (X.T @ (X @ coefficients - y))\n",
    "        coefficients -= learning_rate * gradient\n",
    "    return coefficients\n",
    "\n",
    "# Try multiple learning rates and track best model\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "best_r2_val = -np.inf\n",
    "best_coefficients = None\n",
    "best_learning_rate = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    coefficients = gradient_descent_solver(X_train_bias, y_train, lr, iterations=1000)\n",
    "    y_val_pred = X_val_bias @ coefficients\n",
    "    y_test_pred = X_test_bias @ coefficients\n",
    "\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print results for each learning rate (unchanged)\n",
    "    print(f\"Learning Rate = {lr}\")\n",
    "    print(\"R¬≤ on Validation Set:\", r2_val)\n",
    "    print(\"R¬≤ on Test Set:\", r2_test)\n",
    "    print(\"Beta Coefficients:\\n\", coefficients.flatten()[:5], \"...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    if r2_val > best_r2_val:\n",
    "        best_r2_val = r2_val\n",
    "        best_coefficients = coefficients\n",
    "        best_learning_rate = lr\n",
    "\n",
    "# Print best model details (unchanged)\n",
    "print(\"\\nBest Learning Rate:\", best_learning_rate)\n",
    "print(\"Best Validation R¬≤:\", best_r2_val)\n",
    "print(\"Best Beta Coefficients:\\n\", best_coefficients.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBLgjA2vL1He"
   },
   "source": [
    "Pre-processing and Multiple Linear Regression  \n",
    "Download the dataset regarding Car Price Prediction from the following link:  \n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data  \n",
    "1. Load the dataset with following column names [\"symboling\", \"normalized_losses\",  \n",
    "\"make\", \"fuel_type\", \"aspiration\",\"num_doors\", \"body_style\", \"drive_wheels\",  \n",
    "\"engine_location\", \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",  \n",
    "\"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\", \"stroke\",  \n",
    "\"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]  \n",
    "and replace all ? values with NaN  \n",
    "2. Replace all NaN values with central tendency imputation. Drop the rows with NaN  \n",
    "values in price column  \n",
    "3. There are 10 columns in the dataset with non-numeric values. Convert these values to  \n",
    "numeric values using following scheme:  \n",
    "(i) For ‚Äúnum_doors‚Äù and ‚Äúnum_cylinders‚Äù: convert words (number names) to figures  \n",
    "for e.g., two to 2  \n",
    "(ii) For \"body_style\", \"drive_wheels\": use dummy encoding scheme  \n",
    "(iii) For ‚Äúmake‚Äù, ‚Äúaspiration‚Äù, ‚Äúengine_location‚Äù,fuel_type: use label encoding  \n",
    "scheme  \n",
    "(iv) For fuel_system: replace values containing string pfi to 1 else all values to 0.  \n",
    "(v) For engine_type: replace values containing string ohc to 1 else all values to 0.  \n",
    "4. Divide the dataset into input features (all columns except price) and output variable  \n",
    "(price). Scale all input features.  \n",
    "5. Train a linear regressor on 70% of data (using inbuilt linear regression function of  \n",
    "Python) and test its performance on remaining 30% of data.  \n",
    "6. Reduce the dimensionality of the feature set using inbuilt PCA decomposition and then  \n",
    "again train a linear regressor on 70% of reduced data (using inbuilt linear regression function of python. Does it lead to any perfromance improvement on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVewadlWLztH",
    "outputId": "41ff7c0c-392f-4560-a28b-7871eeb0ec11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression without PCA\n",
      "R¬≤ Score: 0.7895045576733848\n",
      "MSE: 14448999.011837844\n",
      "\n",
      "Linear Regression with PCA\n",
      "R¬≤ Score: 0.7478420860380317\n",
      "MSE: 17308828.207359694\n",
      "\n",
      "‚ùå PCA did not improve performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-949230477.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"num_doors\"] = data[\"num_doors\"].replace(num_map).astype(int)\n",
      "/tmp/ipython-input-949230477.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"num_cylinders\"] = data[\"num_cylinders\"].replace(num_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Column names for the dataset\n",
    "column_names = [\n",
    "    \"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "    \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
    "    \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
    "    \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
    "    \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "car_data = pd.read_csv(dataset_url, names=column_names)\n",
    "\n",
    "# Replace missing values represented as \"?\" with NaN\n",
    "car_data = car_data.replace(\"?\", np.nan)\n",
    "\n",
    "# Impute missing values: mode for categorical, median for numeric\n",
    "for col in car_data.columns:\n",
    "    if car_data[col].dtype == \"object\":\n",
    "        mode_val = car_data[col].mode()[0]\n",
    "        car_data[col] = car_data[col].fillna(mode_val)\n",
    "    else:\n",
    "        car_data[col] = pd.to_numeric(car_data[col], errors=\"coerce\")\n",
    "        median_val = car_data[col].median()\n",
    "        car_data[col] = car_data[col].fillna(median_val)\n",
    "\n",
    "# Remove rows with missing price values\n",
    "car_data = car_data.dropna(subset=[\"price\"])\n",
    "car_data[\"price\"] = car_data[\"price\"].astype(float)\n",
    "\n",
    "# Encode categorical values\n",
    "num_encoding = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "                \"six\": 6, \"eight\": 8, \"twelve\": 12}\n",
    "car_data[\"num_doors\"] = car_data[\"num_doors\"].replace(num_encoding).astype(int)\n",
    "car_data[\"num_cylinders\"] = car_data[\"num_cylinders\"].replace(num_encoding).astype(int)\n",
    "\n",
    "# One-hot encoding for some categorical columns\n",
    "car_data = pd.get_dummies(car_data, columns=[\"body_style\", \"drive_wheels\"], drop_first=True)\n",
    "\n",
    "# Label encoding for selected columns\n",
    "for col in [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]:\n",
    "    encoder = LabelEncoder()\n",
    "    car_data[col] = encoder.fit_transform(car_data[col])\n",
    "\n",
    "# Binary encoding for engine_type and fuel_system\n",
    "car_data[\"fuel_system\"] = car_data[\"fuel_system\"].apply(lambda x: 1 if \"pfi\" in x else 0)\n",
    "car_data[\"engine_type\"] = car_data[\"engine_type\"].apply(lambda x: 1 if \"ohc\" in x else 0)\n",
    "\n",
    "# Split features and target variable\n",
    "X_features = car_data.drop(columns=[\"price\"]).values\n",
    "y_target = car_data[\"price\"].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression without PCA\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "r2_original = r2_score(y_test, y_pred)\n",
    "mse_original = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print results (unchanged)\n",
    "print(\"Linear Regression without PCA\")\n",
    "print(\"R¬≤ Score:\", r2_original)\n",
    "print(\"MSE:\", mse_original)\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "pca_transformer = PCA(n_components=0.95)\n",
    "X_pca = pca_transformer.fit_transform(X_scaled)\n",
    "\n",
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split(X_pca, y_target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression with PCA\n",
    "lr_model_pca = LinearRegression()\n",
    "lr_model_pca.fit(Xp_train, yp_train)\n",
    "yp_pred = lr_model_pca.predict(Xp_test)\n",
    "\n",
    "r2_pca = r2_score(yp_test, yp_pred)\n",
    "mse_pca = mean_squared_error(yp_test, yp_pred)\n",
    "\n",
    "# Print results (unchanged)\n",
    "print(\"\\nLinear Regression with PCA\")\n",
    "print(\"R¬≤ Score:\", r2_pca)\n",
    "print(\"MSE:\", mse_pca)\n",
    "\n",
    "# Performance comparison\n",
    "if r2_pca > r2_original:\n",
    "    print(\"\\n‚úÖ PCA improved performance\")\n",
    "else:\n",
    "    print(\"\\n‚ùå PCA did not improve performance\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
